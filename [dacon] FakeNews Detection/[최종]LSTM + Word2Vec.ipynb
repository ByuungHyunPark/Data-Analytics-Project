{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "from eunjeon import Mecab\n",
    "from konlpy.tag import Hannanum\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding,TimeDistributed,  Input, LSTM, GRU,Bidirectional,  Dropout, Conv1D, MaxPool1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('news_train.csv')\n",
    "test = pd.read_csv('news_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbcf7feba914750beca33d8331b13a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118745.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f09af00958e4229a524aec47c625576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=118745.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3bb8dbf4164ac7b6035bf7f6d04c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=142565.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7ac7b9221240d58a5ecb0f5d0b8406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=142565.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>ord</th>\n",
       "      <th>info</th>\n",
       "      <th>titleToken</th>\n",
       "      <th>contentToken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118740</th>\n",
       "      <td>NEWS01333</td>\n",
       "      <td>20200117</td>\n",
       "      <td>모나리자, 중원 지분 16.88% 양수 결정</td>\n",
       "      <td>미 FDA 임상3상 허가 임박. 묻고 따블로 갈 바이오 황제주.</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[미, fda, 임상, 허가, 임박, 바이오, 제주]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118741</th>\n",
       "      <td>NEWS01333</td>\n",
       "      <td>20200117</td>\n",
       "      <td>모나리자, 중원 지분 16.88% 양수 결정</td>\n",
       "      <td>똑똑해진 소비자..한국도 이젠 소형차 시대</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[똑똑, 해진, 소비자, 한국, 이젠, 소형차, 시대]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118742</th>\n",
       "      <td>NEWS01333</td>\n",
       "      <td>20200117</td>\n",
       "      <td>모나리자, 중원 지분 16.88% 양수 결정</td>\n",
       "      <td>똑똑해진 소비자..한국도 이젠 소형차 시대</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[똑똑, 해진, 소비자, 한국, 이젠, 소형차, 시대]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>NEWS01333</td>\n",
       "      <td>20200117</td>\n",
       "      <td>모나리자, 중원 지분 16.88% 양수 결정</td>\n",
       "      <td>2020년 한국 TV 2대중 1대 인터넷 연결된다</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[한국, tv, 대중, 인터넷, 연결]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118744</th>\n",
       "      <td>NEWS01333</td>\n",
       "      <td>20200117</td>\n",
       "      <td>모나리자, 중원 지분 16.88% 양수 결정</td>\n",
       "      <td>2020년 한국 TV 2대중 1대 인터넷 연결된다</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[한국, tv, 대중, 인터넷, 연결]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n_id      date                     title  \\\n",
       "118740  NEWS01333  20200117  모나리자, 중원 지분 16.88% 양수 결정   \n",
       "118741  NEWS01333  20200117  모나리자, 중원 지분 16.88% 양수 결정   \n",
       "118742  NEWS01333  20200117  모나리자, 중원 지분 16.88% 양수 결정   \n",
       "118743  NEWS01333  20200117  모나리자, 중원 지분 16.88% 양수 결정   \n",
       "118744  NEWS01333  20200117  모나리자, 중원 지분 16.88% 양수 결정   \n",
       "\n",
       "                                    content  ord  info  \\\n",
       "118740  미 FDA 임상3상 허가 임박. 묻고 따블로 갈 바이오 황제주.   48     1   \n",
       "118741              똑똑해진 소비자..한국도 이젠 소형차 시대   49     1   \n",
       "118742              똑똑해진 소비자..한국도 이젠 소형차 시대   50     1   \n",
       "118743          2020년 한국 TV 2대중 1대 인터넷 연결된다   51     1   \n",
       "118744          2020년 한국 TV 2대중 1대 인터넷 연결된다   52     1   \n",
       "\n",
       "                    titleToken                    contentToken  \n",
       "118740  [모나리자, 중원, 지분, 양수, 결정]   [미, fda, 임상, 허가, 임박, 바이오, 제주]  \n",
       "118741  [모나리자, 중원, 지분, 양수, 결정]  [똑똑, 해진, 소비자, 한국, 이젠, 소형차, 시대]  \n",
       "118742  [모나리자, 중원, 지분, 양수, 결정]  [똑똑, 해진, 소비자, 한국, 이젠, 소형차, 시대]  \n",
       "118743  [모나리자, 중원, 지분, 양수, 결정]           [한국, tv, 대중, 인터넷, 연결]  \n",
       "118744  [모나리자, 중원, 지분, 양수, 결정]           [한국, tv, 대중, 인터넷, 연결]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from eunjeon import Mecab\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    token_list = []\n",
    "    stopwords = ['습니다','됩니다','는다' , '으로', 'null', '에서', '으로' , '다고', \n",
    "                 '지만', '된다며', '전년', '라며', '라고', 'nbsp','된다','부터','보다',\n",
    "                '합니다','세요']\n",
    "    #tokenizer = Kkma()\n",
    "    \n",
    "    tokenizer = Mecab()\n",
    "    #tokenizer = Hannanum()\n",
    "    for index, text in enumerate(tqdm(text_list)):\n",
    "        txt = re.sub('[^가-힣a-z新北韓日上中株美]', ' ', text.lower())\n",
    "        #txt = re.sub('&nbsp')\n",
    "        txt = txt.replace('&nbsp', ' ')\n",
    "        txt = txt.strip()\n",
    "        \n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords]\n",
    "        token = [t for t in token if (len(t) >=2) | (t in ['◆','▶','【','%' , '美', '미','러','북','北' , '韓', '日', '中', '上','新','株'])]\n",
    "        token = [i.strip() for i in token]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list\n",
    "\n",
    "\n",
    "\n",
    "train.loc[:, 'titleToken'] = text_preprocessing(train['title'])\n",
    "train.loc[:, 'contentToken'] = text_preprocessing(train['content'])\n",
    "\n",
    "\n",
    "test.loc[:, 'titleToken'] = text_preprocessing(test['title'])\n",
    "test.loc[:, 'contentToken'] = text_preprocessing(test['content'])\n",
    "\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>info</th>\n",
       "      <th>titleToken</th>\n",
       "      <th>contentToken</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>20200117</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[한국, tv, 대중, 인터넷, 연결]</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정, 한국, tv, 대중, 인터넷, 연결]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118744</th>\n",
       "      <td>20200117</td>\n",
       "      <td>1</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정]</td>\n",
       "      <td>[한국, tv, 대중, 인터넷, 연결]</td>\n",
       "      <td>[모나리자, 중원, 지분, 양수, 결정, 한국, tv, 대중, 인터넷, 연결]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  info              titleToken           contentToken  \\\n",
       "118743  20200117     1  [모나리자, 중원, 지분, 양수, 결정]  [한국, tv, 대중, 인터넷, 연결]   \n",
       "118744  20200117     1  [모나리자, 중원, 지분, 양수, 결정]  [한국, tv, 대중, 인터넷, 연결]   \n",
       "\n",
       "                                               text  \n",
       "118743  [모나리자, 중원, 지분, 양수, 결정, 한국, tv, 대중, 인터넷, 연결]  \n",
       "118744  [모나리자, 중원, 지분, 양수, 결정, 한국, tv, 대중, 인터넷, 연결]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train.apply(lambda x : x['titleToken'] + x['contentToken'], axis = 1)\n",
    "test['text'] = test.apply(lambda x : x['titleToken'] + x['contentToken'], axis = 1)\n",
    "\n",
    "train = train.drop(['n_id','ord', 'title', 'content'], axis =1)\n",
    "test = test.drop(['n_id','ord', 'title', 'content'], axis =1)\n",
    "\n",
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word2vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTit = [i.split() for i in list(set(train['titleToken'].apply(lambda x : ' '.join(x))))]\n",
    "trainCont = [i.split() for i in list(set(train['contentToken'].apply(lambda x : ' '.join(x))))]\n",
    "testTit = [i.split() for i in list(set(test['titleToken'].apply(lambda x : ' '.join(x))))]\n",
    "testCont = [i.split() for i in list(set(test['contentToken'].apply(lambda x : ' '.join(x))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train['text']\n",
    "y = train['info'].values\n",
    "\n",
    "\n",
    "#네이버뉴스 데이터를 통해 학습한 모델 사용\n",
    "w2v_model = gensim.models.Word2Vec.load(\"NaverNewsW2V.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코로나 -> 1\n",
      "종목 -> 2\n",
      "한국 -> 3\n",
      "가능 -> 4\n",
      "이상 -> 5\n",
      "투자 -> 6\n",
      "시장 -> 7\n",
      "공개 -> 8\n",
      "주식 -> 9\n",
      "경제 -> 10\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 650\n",
    "\n",
    "#Making all news of size maxlen defined above\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(w2v_model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감, 코스닥, 기관, 순매도, 데일리, marketpoint, 현재, 코스닥, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감, 코스닥, 기관, 순매도, 실적, 기반, 저가, 매집, 해야, 급등, 유망주...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감, 코스닥, 기관, 순매도, 하이스, 탁론, 선취, 수수료, 최저, 금리, 상...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200605</td>\n",
       "      <td>[마감, 코스닥, 기관, 순매도, 종합, 경제, 정보, 미디어, 데일리, 무단, 전...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 전국, 소비, 조성, 기여, 예정]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 데일리, 권오석, 기자, 중소,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 대한민국, 동행, 세일, 라이브...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 권역, 현장, 행사, 오프라인,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 이번, 동행, 세일, 롯데, 공...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 동행, 세일, 기간, 쇼핑, 판...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 방송, 공영, 쇼핑, 마스크, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 특히, 롯데, 쇼핑, 부산, 벡...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 박영선, 중기, 장관, 호스트,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 현장, 방송, 다음, 주자, 공...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 박영선, 장관, 이번, 동행, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 한편, 앞서, 중기, 따르, 지...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 실적, 기반, 저가, 매집, 해...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 하이스, 탁론, 선취, 수수료,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20200626</td>\n",
       "      <td>[롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 종합, 경제, 정보, 미디어, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, gtx, 노선, 내년, 착공, 확정, 지구,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 양주, 도시, 회천, 지구, 처음, 공급, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 비해, 개발, 지연, 회천, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 순위, 청약, 결과, 청약, 평균, 기록, 때문]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 지난, 분양, 순위, 미달, 양주, 도시, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 수도, 도시, 경기도, 양주, 도시, 회천,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 양주, 도시, 양주시, 지구, 지정, 옥정,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 위례, 도시, 면적, 판교, 도시, 규모, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 하지만, 도시, 성남, 판교, 파주, 운정,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 특히, 회천, 지구, 옥정, 지구, 개발, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 가구, 규모, 옥정, 센트럴,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 하지만, 회천, 지구, 지구, 지정, 이후,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 상황, 달라진, 지난해, 하반기]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 회천, 지구, 맞닿, 덕정역, 수원, 까지,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 함께, 최근, 한국, 철도, 회천, 지구, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, lh, 회천, 지구, 택지, 분양, 적극, 나서]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 일반, 상업, 용지, 필지, 규모, 공공, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 지난, 회천, 지구, 블록, 블록, 공공, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 양주시, 현지, 옥정, 지구, 회천, 지구,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 호선, 연장, 완공, 목표, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 경기도, 추진, 양주, 테크, 노벨리, 회천...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 덕계동, 공인, 중개, 사무소, 관계자, 회...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, lh, 관계자, 지난해, 하반기, 기점, 회...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 실적, 기반, 저가, 매집, 해야, 급등, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 하이스, 탁론, 선취, 수수료, 최저, 금리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20200518</td>\n",
       "      <td>[늦깎이, 개발, 양주, 회천, 봄볕, 종합, 경제, 정보, 미디어, 데일리, 무단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20200522</td>\n",
       "      <td>[bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 오후, bmw, 온라인...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20200522</td>\n",
       "      <td>[bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 데일리, 송승현, 기자...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20200522</td>\n",
       "      <td>[bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 퍼스트, 에디션, 세계...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20200522</td>\n",
       "      <td>[bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 먼저, bmw, 인디,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20200522</td>\n",
       "      <td>[bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 아울러, 블랙, 키드니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  info\n",
       "0   20200605  [마감, 코스닥, 기관, 순매도, 데일리, marketpoint, 현재, 코스닥, ...     0\n",
       "1   20200605  [마감, 코스닥, 기관, 순매도, 실적, 기반, 저가, 매집, 해야, 급등, 유망주...     1\n",
       "2   20200605  [마감, 코스닥, 기관, 순매도, 하이스, 탁론, 선취, 수수료, 최저, 금리, 상...     1\n",
       "3   20200605  [마감, 코스닥, 기관, 순매도, 종합, 경제, 정보, 미디어, 데일리, 무단, 전...     0\n",
       "4   20200626   [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 전국, 소비, 조성, 기여, 예정]     0\n",
       "5   20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 데일리, 권오석, 기자, 중소,...     0\n",
       "6   20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 대한민국, 동행, 세일, 라이브...     0\n",
       "7   20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 권역, 현장, 행사, 오프라인,...     0\n",
       "8   20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 이번, 동행, 세일, 롯데, 공...     0\n",
       "9   20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 동행, 세일, 기간, 쇼핑, 판...     0\n",
       "10  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 방송, 공영, 쇼핑, 마스크, ...     0\n",
       "11  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 특히, 롯데, 쇼핑, 부산, 벡...     0\n",
       "12  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 박영선, 중기, 장관, 호스트,...     0\n",
       "13  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 현장, 방송, 다음, 주자, 공...     0\n",
       "14  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 박영선, 장관, 이번, 동행, ...     0\n",
       "15  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 한편, 앞서, 중기, 따르, 지...     0\n",
       "16  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 실적, 기반, 저가, 매집, 해...     1\n",
       "17  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 하이스, 탁론, 선취, 수수료,...     1\n",
       "18  20200626  [롯데, 공영, tv, 쇼핑, 동행, 세일, 동참, 종합, 경제, 정보, 미디어, ...     0\n",
       "19  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, gtx, 노선, 내년, 착공, 확정, 지구,...     0\n",
       "20  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 양주, 도시, 회천, 지구, 처음, 공급, ...     0\n",
       "21  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 비해, 개발, 지연, 회천, ...     0\n",
       "22  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 순위, 청약, 결과, 청약, 평균, 기록, 때문]     0\n",
       "23  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 지난, 분양, 순위, 미달, 양주, 도시, ...     0\n",
       "24  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 수도, 도시, 경기도, 양주, 도시, 회천,...     0\n",
       "25  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 양주, 도시, 양주시, 지구, 지정, 옥정,...     0\n",
       "26  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 위례, 도시, 면적, 판교, 도시, 규모, ...     0\n",
       "27  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 하지만, 도시, 성남, 판교, 파주, 운정,...     0\n",
       "28  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 특히, 회천, 지구, 옥정, 지구, 개발, ...     0\n",
       "29  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 가구, 규모, 옥정, 센트럴,...     0\n",
       "30  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 하지만, 회천, 지구, 지구, 지정, 이후,...     0\n",
       "31  20200518           [늦깎이, 개발, 양주, 회천, 봄볕, 상황, 달라진, 지난해, 하반기]     0\n",
       "32  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 회천, 지구, 맞닿, 덕정역, 수원, 까지,...     0\n",
       "33  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 함께, 최근, 한국, 철도, 회천, 지구, ...     0\n",
       "34  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, lh, 회천, 지구, 택지, 분양, 적극, 나서]     0\n",
       "35  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 일반, 상업, 용지, 필지, 규모, 공공, ...     0\n",
       "36  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 지난, 회천, 지구, 블록, 블록, 공공, ...     0\n",
       "37  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 양주시, 현지, 옥정, 지구, 회천, 지구,...     0\n",
       "38  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 옥정, 지구, 호선, 연장, 완공, 목표, ...     0\n",
       "39  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 경기도, 추진, 양주, 테크, 노벨리, 회천...     0\n",
       "40  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 덕계동, 공인, 중개, 사무소, 관계자, 회...     0\n",
       "41  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, lh, 관계자, 지난해, 하반기, 기점, 회...     0\n",
       "42  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 실적, 기반, 저가, 매집, 해야, 급등, ...     1\n",
       "43  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 하이스, 탁론, 선취, 수수료, 최저, 금리...     1\n",
       "44  20200518  [늦깎이, 개발, 양주, 회천, 봄볕, 종합, 경제, 정보, 미디어, 데일리, 무단...     0\n",
       "45  20200522  [bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 오후, bmw, 온라인...     0\n",
       "46  20200522  [bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 데일리, 송승현, 기자...     0\n",
       "47  20200522  [bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 퍼스트, 에디션, 세계...     0\n",
       "48  20200522  [bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 먼저, bmw, 인디,...     0\n",
       "49  20200522  [bmw, 코리아, 온라인, 정판, 퍼스트, 에디션, 출시, 아울러, 블랙, 키드니...     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['date','text','info']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "saveBestweights = ModelCheckpoint('best.weights', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlyStopping   = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83121, 650) (35624, 650)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(pd.DataFrame(X), y, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim = EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
    "#model.add(Conv1D(activation='relu', filters=3, kernel_size=3))\n",
    "#model.add(MaxPool1D())\n",
    "#LSTM \n",
    "model.add(LSTM(units=64))\n",
    "#model.add(Bidirectional(LSTM(units=16 )))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 650, 200)          7177000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 7,244,905\n",
      "Trainable params: 67,905\n",
      "Non-trainable params: 7,177,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_3207]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-665bfbda3d3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveBestweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_3207]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "#갑자기 에러뜸,, GPU 문제일듯\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=20, callbacks=[earlyStopping, saveBestweights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "valPred = model.predict(X_val)\n",
    "y_pred = (valPred >= 0.5).astype(\"int\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCheck = pd.read_csv('news_train.csv')\n",
    "trainCheck = trainCheck.loc[X_val.index]\n",
    "trainCheck['pred'] = valPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "subLabel = model.predict(testX)\n",
    "subLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### submit 파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['pred'] = subLabel\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainCheck = pd.read_csv('news_train.csv')\n",
    "testCheck = pd.read_csv('news_test.csv')\n",
    "testCheck['pred'] = subLabel\n",
    "testCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['info'] = testCheck['predInfo'].astype(int)\n",
    "submit.to_csv('submit/1215.csv', index = False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
